\chapter{Descartes' rule of signs}
\label{sec:descartes}
Descartes' rule of signs is a very useful way to study the existence and sign of the roots of a polynomial without having to express them explicitely.
\begin{atheorem}[Descartes' rule of signs]\label{th:descartes}
Let $p(x) = \sum_{i=0}^m a_ix^i $ be a polynomial with real coefficients such that $a_m \neq 0$.
Define $v$ to be the number of {\it variations in sign} of the sequence of coefficients $a_m, \ldots, a_0$. By `variations in sign' we mean the number of values of $n$ such that the sign of $a_n$ differs from the sign of $a_{n - 1}$, as $n$ ranges from $m$ down to 1.
Then 
\begin{itemize}
\item the number of positive real roots of $p(x)$ is $v-2N$ for some integer $N$ satisfying $0 \leq N \leq \dfrac{v}{2}$,
\item the number of negative roots of $p(x)$ may be obtained by the same method by applying the rule of signs to $p(-x)$.
\end{itemize}
\end{atheorem}


\begin{example}
Let $p(x) = x^3+3x^2-x-3$. The coefficients have sign $++--$, so there is one sign change.
Thus $v = 1$. Since $0 \leq N \leq 1/2$, we must have $N=0$. Thus $v-2N=1$ and there is exactly one positive real root of $p(x)$.

To find the negative roots, we examine $p(-x) = -x^3+3x^2+x-3$. The coefficients have sign $-++-$, so there are two sign changes. Thus $v=2$ and $0 \leq N \leq 2/2= 1$.
Thus, there are two possible solutions, $N=0$ and $N=1$, and two possible values of $v-2N$. Therefore, there are either two or no negative real roots.
Furthermore, note that $p(-1)=(-1)^3+3 \cdot (-1)^2-(-1)-3=0$, hence there is at least one negative root. Therefore there must be exactly two.
\end{example}

% \frame{\frametitle{Descartes' rule of signs}
% \begin{theorem}[Descartes' rule of signs]\label{th:descartes}
% Let $p(x) = \sum_{i=0}^m a_ix^i $ be a polynomial with real coefficients such that $a_m \neq 0$.
% Define $v$ to be the number of {\it variations in sign} of the sequence of coefficients $a_m, \ldots, a_0$. By 'variations in sign' we mean the number of values of $n$ such that the sign of $a_n$ differs from the sign of $a_{n - 1}$, as $n$ ranges from $m$ down to 1.
% Then 
% \begin{itemize}
% \item the number of positive real roots of $p(x)$ is $v-2N$ for some integer $N$ satisfying $0 \leq N \leq \dfrac{v}{2}$,
% \item the number of negative roots of $p(x)$ may be obtained by the same method by applying the rule of signs to $p(-x)$.
% \end{itemize}
% \end{theorem}
% }
% 
% \frame{\frametitle{Example of use of Descartes' rule}
% \begin{example}
% Let 
% \[
% p(x) = x^3+3x^2-x-3.
% \] 
% Coefficients have signs $++--$, i.e., 1 sign change.
% Thus $v = 1$. Since $0 \leq N \leq 1/2$, we must have $N=0$. Thus $v-2N=1$ and there is exactly one positive real root of $p(x)$.
% 
% To find the negative roots, we examine $p(-x) = -x^3+3x^2+x-3$. Coefficients have signs $-++-$, i.e., 2 sign changes. Thus $v=2$ and $0 \leq N \leq 2/2= 1$.
% Thus, there are two possible solutions, $N=0$ and $N=1$, and two possible values of $v-2N$. Therefore, there are either two or no negative real roots.
% Furthermore, note that $p(-1)=(-1)^3+3 \cdot (-1)^2-(-1)-3=0$, hence there is at least one negative root. Therefore there must be exactly two.
% \end{example}
% }


\chapter{Eigenvalues and eigenvectors}
\label{app:spectral}

\section{Eigenvalues and (right) eigenvectors}
Let $M\in\M_n(\IF)$ with $\IF=\IR$ or $\IC$. The \textbf{eigenvalues} of $M$ are numbers $\lambda\in\IC$ found by solving the equation
\begin{equation}\label{eq:eigenvalue_eq}
\det(M-\lambda\II)=0,
\end{equation}
where $\II$ is the identity matrix of $\M_n(\IF)$, and $v\in\IF^n$. Another way to write \eqref{eq:eigenvalue_eq} is as
\[
Mv=\lambda v.
\]
It is easy to see that these two expressions are equivalent. If $M\in\M_n(\IR)$, then there are exactly $n$ eigenvalues in $\IC$ (or $\IR$), including multiplicity. This set of values is called the \textbf{spectrum} of $M$, and is usually denoted $\Sp(M)$ or $\textrm{spec}(M)$. In other words,
\[
\Sp(M)=\{\lambda\in\IC:\det(M-\lambda\II)=0\textrm{ for some }v\in\IC^n\}.
\]
Note that eigenvalues are \emph{matrix invariants}, in the sense that they are preserved by linear transformations of the vector space. (Other examples of matrix invariants include the rank, the determinant and the trace.)
Another name for \eqref{eq:eigenvalue_eq} is the \textbf{characteristic polynomial}, which is obtained by considering the polynomial resulting from \eqref{eq:eigenvalue_eq},
\[
P(\lambda)=\det(M-\lambda\II).
\]
Eigenvalues of $M$ are then the roots of $P(\lambda)$.

To a given eigenvalue $\lambda_i\in\Sp(M)$, there corresponds an \textbf{eigenvector} $v_i$ which satisfies the equation \eqref{eq:eigenvalue_eq} for $\lambda=\lambda_i$.


\section{Left eigenvectors}
Let $M$ be an $r\times r$ matrix, $u,v$ be two column vectors, $\lambda\in\IR$. Then, if  
\[
Mu=\lambda u,
\]
$u$ is the (right) eigenvector corresponding to $\lambda$, and if
\[
v^TM=\lambda v^T
\]
then $v$ is the left eigenvector corresponding to $\lambda$. Note that to a given eigenvalue there corresponds (to a multiple) one left and one right eigenvector.


\chapter{Tools to determine properties of eigenvalues}
\begin{atheorem}(Routh-Hurwitz Criteria)
Given the polynomial,
$$P(\lambda)=\lambda ^n + a_1 \lambda ^{n-1}+\dots + a_{n-1}\lambda +a_n$$
where the coefficients $a_i$ are real constants, $i=1,\dots , n$ define the $n$ Hurwitz matrices using the coefficients $a_i$ of the characteristic polynomial:
$$H_1=(a_1),\quad H_2=\left (\begin{array}{cc}a_1 & 1 \\ a_3 &a_2\end{array}\right), \quad H_3=\left (\begin{array}{ccc}a_1 & 1 & 0 \\ a_3 &a_2 &a_1 \\ a_5& a_4 & a_3\end{array}\right),$$
and
$$H_n=\left (\begin{array}{cccccc}a_1 & 1 & 0 & 0 & \dots &0\\ a_3& a_2 & a_1 & 1 & \dots & 0 \\ a_5 & a_4 & a_3 & a_2 & \dots &0\\\vdots & \vdots & \vdots & \vdots & \dots & \vdots \\ 0 & 0& 0& 0& \dots & a_n\end{array}\right )$$
where $a_j=0$ if $j>n$. All of the roots of the polynomial $P(\lambda)$ are negative or have negative real part if and only if the determinants of all Hurwitz matrices are positive:
$$\det H_i>0, \quad j=1,2,\dots, n.$$
\end{atheorem}



\begin{atheorem}(Corollary)
Routh-Hurwitz criteria for $n=2,3,4,5$
\begin{itemize}
\item $n=2:$ $a_1>0$ and $a_2>0$.
\item $n=3:$ $a_1>0,$ $a_3>0$ and $a_1a_2>a_3$.
\item $n=4:$ $a_1>0,$ $a_3>0,$ $a_4>0$  and $a_1a_2a_3>a_3^2+a_1^2a_4$.
\item $n=5:$ $a_i>0,$ $i=1,2,3,4,5,$ $a_1a_2a_3>a_3^2+a_1^2a_4$ and $(a_1a_4-a_5)(a_1a_2a_3-a_3^2-a_1^2a_4)>a_5(a_1a_2-a_3)^2+a_1a_5^2$
\end{itemize}
\end{atheorem}



\begin{atheorem}(Gerhgorin's Theorem)
Let $A$ be an $n\times n$ matrix. Let $D_i$ be the disk in the complex plane with the center at $a_{ii}$ and radius $r_i=\sum _{j=1,j\not =i}^n|a_{ij}|$. Then all eigenvalues of the matrix $A$ lie in the union of the disks $D_i$, $i=1,2,\dots, n$, $\cup_{i=1}^nD_i$. In particular, if $\lambda $ is an eigenvalue of $A$, then for some $i=1,2,\dots,n$
$$|\lambda -a_{ii}|\leq r_i.$$
\end{atheorem}

\begin{atheorem}(Corollary)
Let $A$ be an $n\times n$ matrix with real entries. If the diagonal elements of $A$ satisfy 
$$a_{ii}<-r_{i} \quad where \quad r_i=\sum _{j=1,j\not =i}^n|a_{ij}|$$
for $i=1,2,\dots,n$ then the eigenvalues of $A$ are negative or have have negative real part.
\end{atheorem}


